{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Pathology using TPU-DenseNetMoblile\n",
    "I have used the prebuild model in keras - Keras Application.Keras Applications are deep learning models that are made available alongside pre-trained weights. You can read more about them [here](https://keras.io/applications/).\n",
    "1. [Pre-processing Images](#head1)\n",
    "2. [CNN Model](#head2)\n",
    "  * [Load in pre-trained model](#head2a)\n",
    "  * [Add Final trainable layers to pre-built model](#head2b)\n",
    "  * [Learing Rate Scheduler](#head2c)\n",
    "3. [Evaluation and training curves.](#head3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "%matplotlib inline\n",
    "scale_percent = 30\n",
    "# width = int(1365 * scale_percent / 100)\n",
    "# height = int(2048 * scale_percent / 100)\n",
    "width = 512\n",
    "height = 512\n",
    "dim = (width, height)\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "batch_size = 16*tpu_strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://kds-44c8a6f93070fa89189427ff10c4c0530ab3f532ac92907ab3c2bb58'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
    "GCS_DS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def ImageIDtodir(label):\n",
    "    return GCS_DS_PATH+'/images/' + label + '.jpg'\n",
    "train_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\n",
    "train_dir = train_df['image_id'].apply(ImageIDtodir).values\n",
    "test_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\n",
    "test_dir = test_df['image_id'].apply(ImageIDtodir).values\n",
    "y =  train_df.loc[:, 'healthy':].values\n",
    "train_dir, valid_dir, y_train, y_val = train_test_split(train_dir,y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"head1\"></a>1.Pre-processing Images \n",
    "we are using tensorflow tensor_from_slices to read images while training directly from the file.Images are reshaped to 512x512x3.\n",
    "I am also splitting the train images into training and validation with a validation split of 0.15.   \n",
    "The train images are flipped randomly but no such pre-processing is done on validation or train images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename, label=None,image_size=(width,height)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image,image_size)   \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "    \n",
    "\n",
    "def augment(image, label=None):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((train_dir, y_train))\n",
    "    .map(load_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .map(augment, num_parallel_calls=AUTO)\n",
    "    .repeat()\n",
    "    .shuffle(512)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((valid_dir,y_val))\n",
    "    .map(load_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(test_dir)\n",
    "    .map(load_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .batch(batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"head2\"></a>2. CNN Model\n",
    "\n",
    "## A. <a name=\"head2a\"></a>Load in Pre-trained model.\n",
    "I have used the DenseNetMobile in-built model with pre-trained weights. You can read about other Keras Applications [here](https://keras.io/applications/#available-models).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. <a name=\"head2b\"></a>Add Final trainable Layers to pre-built model.\n",
    "As we need to categories the images into 4 labels we need to add another layer to the model.     \n",
    "The ouput of the DenseNet model which are essentially features extracted from the images are passed on to more layers-\n",
    "* A Global average pooling layer\n",
    "* A Dropout layer with rate 0.3\n",
    "* A Dense layer with 50 units and relu activation.\n",
    "* A Dense layer with 4 units and softmax activation.  \n",
    "   \n",
    "The last layer is which gives out the precitions.   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "with tpu_strategy.scope():\n",
    "    DenseNetModel = tf.keras.applications.DenseNet121(input_shape=(width,height,3),\n",
    "                                              weights='imagenet',\n",
    "                                              include_top=False)\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [DenseNetModel,\n",
    "#             tf.keras.layers.Convolution2D(1024,(5,5),strides=(2,2),activation='relu'),\n",
    "#             tf.keras.layers.Convolution2D(2048,(4,4),strides=(2,2),activation='relu'),\n",
    "#             tf.keras.layers.AveragePooling2D((5,5),2),\n",
    "#             tf.keras.layers.AveragePooling2D((4,4),2),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(50, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')]\n",
    "    )\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy',tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 16, 16, 1024)      7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                51250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 7,088,958\n",
      "Trainable params: 7,005,310\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"head2b\"></a> Learing Rate Scheduler\n",
    "We have to reduce our learning mid-training as the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate schedular\n",
    "def lr_scheduler(epoch, lr):\n",
    "    decay_rate = 0.5\n",
    "    decay_step = 5\n",
    "    if epoch % decay_step == 0 and epoch:\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 14 steps, validate for 3 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 1/25\n",
      "14/14 [==============================] - 219s 16s/step - loss: 0.6901 - accuracy: 0.7690 - auc: 0.9274 - val_loss: 24.4483 - val_accuracy: 0.3577 - val_auc: 0.5718\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 6s 418ms/step - loss: 0.3212 - accuracy: 0.9029 - auc: 0.9799 - val_loss: 47.2992 - val_accuracy: 0.3577 - val_auc: 0.5718\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 6s 408ms/step - loss: 0.2194 - accuracy: 0.9330 - auc: 0.9891 - val_loss: 14.1203 - val_accuracy: 0.3577 - val_auc: 0.5735\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 6s 406ms/step - loss: 0.2048 - accuracy: 0.9353 - auc: 0.9903 - val_loss: 3.4105 - val_accuracy: 0.4526 - val_auc: 0.7101\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 6s 400ms/step - loss: 0.1603 - accuracy: 0.9492 - auc: 0.9940 - val_loss: 3.7619 - val_accuracy: 0.3905 - val_auc: 0.6730\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 6s 402ms/step - loss: 0.1242 - accuracy: 0.9648 - auc: 0.9960 - val_loss: 6.0834 - val_accuracy: 0.4489 - val_auc: 0.6574\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 6s 399ms/step - loss: 0.0836 - accuracy: 0.9754 - auc: 0.9984 - val_loss: 7.0090 - val_accuracy: 0.5036 - val_auc: 0.6955\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 6s 415ms/step - loss: 0.0840 - accuracy: 0.9732 - auc: 0.9983 - val_loss: 0.9242 - val_accuracy: 0.8102 - val_auc: 0.9186\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 6s 413ms/step - loss: 0.0629 - accuracy: 0.9844 - auc: 0.9987 - val_loss: 0.3401 - val_accuracy: 0.9124 - val_auc: 0.9738\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 6s 414ms/step - loss: 0.0516 - accuracy: 0.9838 - auc: 0.9995 - val_loss: 0.5391 - val_accuracy: 0.8905 - val_auc: 0.9598\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 6s 408ms/step - loss: 0.0430 - accuracy: 0.9888 - auc: 0.9993 - val_loss: 0.3711 - val_accuracy: 0.9015 - val_auc: 0.9747\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 6s 412ms/step - loss: 0.0420 - accuracy: 0.9855 - auc: 0.9997 - val_loss: 0.3845 - val_accuracy: 0.8759 - val_auc: 0.9680\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 6s 409ms/step - loss: 0.0389 - accuracy: 0.9911 - auc: 0.9989 - val_loss: 0.2616 - val_accuracy: 0.9015 - val_auc: 0.9750\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 6s 415ms/step - loss: 0.0199 - accuracy: 0.9950 - auc: 0.9996 - val_loss: 0.3554 - val_accuracy: 0.8978 - val_auc: 0.9661\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 6s 403ms/step - loss: 0.0185 - accuracy: 0.9950 - auc: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.8832 - val_auc: 0.9629\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 6s 413ms/step - loss: 0.0191 - accuracy: 0.9933 - auc: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.8905 - val_auc: 0.9694\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 5s 391ms/step - loss: 0.0301 - accuracy: 0.9922 - auc: 0.9995 - val_loss: 0.3393 - val_accuracy: 0.8942 - val_auc: 0.9632\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 6s 410ms/step - loss: 0.0239 - accuracy: 0.9944 - auc: 0.9995 - val_loss: 0.2481 - val_accuracy: 0.9307 - val_auc: 0.9770\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 6s 407ms/step - loss: 0.0175 - accuracy: 0.9939 - auc: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9270 - val_auc: 0.9852\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 6s 412ms/step - loss: 0.0144 - accuracy: 0.9950 - auc: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9270 - val_auc: 0.9835\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 6s 399ms/step - loss: 0.0064 - accuracy: 0.9989 - auc: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9307 - val_auc: 0.9828\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 6s 410ms/step - loss: 0.0185 - accuracy: 0.9939 - auc: 0.9999 - val_loss: 0.2095 - val_accuracy: 0.9343 - val_auc: 0.9805\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 6s 401ms/step - loss: 0.0107 - accuracy: 0.9978 - auc: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9343 - val_auc: 0.9811\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 6s 412ms/step - loss: 0.0131 - accuracy: 0.9961 - auc: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9416 - val_auc: 0.9834\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 6s 406ms/step - loss: 0.0096 - accuracy: 0.9989 - auc: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9416 - val_auc: 0.9876\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=25,\n",
    "                    callbacks=callbacks,\n",
    "                    steps_per_epoch=y.shape[0] // batch_size,\n",
    "                    validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"head3\"></a>3. Evaluation and training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 118s 8s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_dataset,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0</td>\n",
       "      <td>1.199259e-03</td>\n",
       "      <td>0.009532</td>\n",
       "      <td>9.891158e-01</td>\n",
       "      <td>1.526450e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_1</td>\n",
       "      <td>1.022515e-04</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>9.990321e-01</td>\n",
       "      <td>5.232752e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_2</td>\n",
       "      <td>8.236055e-05</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.121791e-05</td>\n",
       "      <td>9.998840e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_3</td>\n",
       "      <td>9.999143e-01</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>8.458936e-06</td>\n",
       "      <td>7.151408e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_4</td>\n",
       "      <td>3.958382e-06</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>9.998214e-01</td>\n",
       "      <td>2.583578e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Test_1816</td>\n",
       "      <td>5.730747e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>9.999930e-01</td>\n",
       "      <td>7.927180e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Test_1817</td>\n",
       "      <td>3.252980e-02</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>3.782881e-03</td>\n",
       "      <td>9.575266e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Test_1818</td>\n",
       "      <td>9.203129e-07</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>9.999844e-01</td>\n",
       "      <td>7.476804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>Test_1819</td>\n",
       "      <td>9.999589e-01</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.900764e-07</td>\n",
       "      <td>3.815549e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>Test_1820</td>\n",
       "      <td>2.652995e-05</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>5.921698e-06</td>\n",
       "      <td>9.998858e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id       healthy  multiple_diseases          rust          scab\n",
       "0        Test_0  1.199259e-03           0.009532  9.891158e-01  1.526450e-04\n",
       "1        Test_1  1.022515e-04           0.000813  9.990321e-01  5.232752e-05\n",
       "2        Test_2  8.236055e-05           0.000022  1.121791e-05  9.998840e-01\n",
       "3        Test_3  9.999143e-01           0.000006  8.458936e-06  7.151408e-05\n",
       "4        Test_4  3.958382e-06           0.000149  9.998214e-01  2.583578e-05\n",
       "...         ...           ...                ...           ...           ...\n",
       "1816  Test_1816  5.730747e-08           0.000006  9.999930e-01  7.927180e-07\n",
       "1817  Test_1817  3.252980e-02           0.006161  3.782881e-03  9.575266e-01\n",
       "1818  Test_1818  9.203129e-07           0.000014  9.999844e-01  7.476804e-07\n",
       "1819  Test_1819  9.999589e-01           0.000002  5.900764e-07  3.815549e-05\n",
       "1820  Test_1820  2.652995e-05           0.000082  5.921698e-06  9.998858e-01\n",
       "\n",
       "[1821 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\n",
    "submission = pd.DataFrame(\n",
    "    {'image_id': temp_df['image_id'],\n",
    "     'healthy': predictions[:,0],\n",
    "     'multiple_diseases': predictions[:,1],\n",
    "     'rust': predictions[:,2],\n",
    "     'scab': predictions[:,3],\n",
    "    })\n",
    "submission.to_csv(\"plant_pathology.csv\",index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
